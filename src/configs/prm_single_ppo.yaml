ENV_PARAMETERS:
  num_frames: 3
  num_agent: 1
  ep_length: 200
  num_envs: 4
  num_cpus: 4
  map: "SMALL_HARVEST_MAP"
  agent_view_range: 5

RL_PARAMETERS:
  learner: "ppo"
  spawn_speed: "fast"
  learning_rate: 0.0001
  batch_size:  1000
  ent_coef: 0.01
  gamma: 0.99
  gae_lambda: 1
  target_kl: 0.01
  max_grad_norm: 40
  policy: MlpPolicy
  render_frequency: 30
  n_steps: 1000
  n_epochs: 2
  vf_coef : .5
  clip_range: .2
  features_dim: 128  # output layer of cnn extractor AND shared layer for policy and value functions
  buffer_size: 500
  
EXPERIMENT_PARAMETERS:
  gpu_id: 1
  run_name_template: "{experiment}-{metric}-{spawn_speed}-{num_agents}_agents"
  penalty: False
  metric: "Efficiency"
  independent: False
  experiment: "prm-single"
  debug: False
  n_episodes: 15_000

RP_PARAMETERS:
  learning_starts: 1
  batch_size: 4
  train_freq: 1
  predictor_epochs: 8
  lr: 0.0005
  emb_dim: 32
  features_dim: 512
  fcnet_hiddens: [64, 32, 16]
  network: "OneHotCnnNetwork" # options -> [EmbedCnnNetwork, OneHotCnnNetwork]
  
    