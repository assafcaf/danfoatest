ENV_PARAMETERS:
  num_frames: 3
  num_agent: 7
  ep_length: 600
  num_envs: 4
  num_cpus: 4
  map: 'HARVEST_MAP'
  agent_view_range: 7

RL_PARAMETERS:
  learner: "dqn"
  spawn_speed: "fast"
  learning_rate: 0.0005
  batch_size: 128
  tau: 0.035
  gamma: 0.99
  train_freq: 4
  exploration_fraction: 0.35
  exploration_final_eps: 0.03
  learning_starts: 1_500_000
  buffer_size: 500
  policy: MlpPolicy
  render_frequency: 25
  features_dim: 128  # output layer of cnn extractor AND shared layer for policy and value functions

EXPERIMENT_PARAMETERS:
  penalty: False
  metric: "Efficiency"

  # metric: "Efficiency*Sustainability"
  experiment: "prm"
  independent: False 
  run_name_template: "{experiment}-{metric}-{spawn_speed}-{num_agents}_agents"
  gpu_id: 0
  debug: False
  n_episodes: 6_000


RP_PARAMETERS:
  learning_starts: 1
  batch_size: 32
  train_freq: 1
  predictor_epochs: 3
  lr: 0.0005
  emb_dim: 32
  features_dim: 512
  fcnet_hiddens: [64, 32, 16]
  network: "OneHotCnnNetwork" # options -> [EmbedCnnNetwork, OneHotCnnNetwork]
  
    
    