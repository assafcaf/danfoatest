ENV_PARAMETERS:
  num_frames: 2
  num_agent: 4
  ep_length: 400
  num_envs: 4
  num_cpus: 4
  map: 'MEDIUM2_HARVEST_MAP'
  agent_view_range: 7

RL_PARAMETERS:
  learner: "dqn"
  spawn_speed: "fast"
  learning_rate: 0.0005
  batch_size: 128
  tau: 0.035
  gamma: 0.99
  train_freq: 4
  exploration_fraction: 0.35
  exploration_final_eps: 0.03
  learning_starts: 1_500_000
  buffer_size: 1000
  policy: MlpPolicy
  render_frequency: 50
  features_dim: 128  # output layer of cnn extractor AND shared layer for policy and value functions

EXPERIMENT_PARAMETERS:
  penalty: False
  # metric: "Efficiency2"
  # metric: "Efficiency*Sustainability"
  metric: "Efficiency*Peace"
  # metric: "Efficiency*Peace2"
  experiment: "prm"
  independent: False 
  run_name_template: "{experiment}-{metric}-{spawn_speed}-{num_agents}_agents"
  gpu_id: 1
  debug: False
  n_episodes: 8_000


RP_PARAMETERS:
  learning_starts: 32
  batch_size: 32
  train_freq: 5
  predictor_epochs: 3
  lr: 0.0005
  emb_dim: 32
  features_dim: 512
  fcnet_hiddens: [64, 32, 16]
  network: "OneHotCnnNetwork" # options -> [EmbedCnnNetwork, OneHotCnnNetwork]
  episodial: False
  # episodial: True
  # subsequent: False
  
    
    